/**
 * ì˜ì–´ ë¬¸ì¥ ìƒì„± API Route
 * í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ë™ì  LLM ì„ íƒ êµ¬í˜„
 */

import { NextRequest, NextResponse } from 'next/server';
import { callLLM } from '@/lib/llm-client';
import { validateLLMConfig } from '@/lib/llm-config';

export interface GenerateSentenceRequest {
  text: string;
  level: 'ì´ˆê¸‰' | 'ì¤‘ê¸‰' | 'ê³ ê¸‰';
}

export interface GenerateSentenceResponse {
  sentences: string[];
  provider?: string;  // ì–´ë–¤ LLMì„ ì‚¬ìš©í–ˆëŠ”ì§€ ë°˜í™˜
}

export async function POST(request: NextRequest) {
  try {
    // ğŸ” ì„œë²„ ì‹œì‘ ì‹œ í™˜ê²½ë³€ìˆ˜ ê²€ì¦
    const configValidation = validateLLMConfig();
    if (!configValidation.isValid) {
      console.error('âŒ LLM ì„¤ì • ì˜¤ë¥˜:', configValidation.errors);
      return NextResponse.json(
        { error: 'LLM API ì„¤ì •ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.', details: configValidation.errors },
        { status: 500 }
      );
    }

    // âš ï¸ ê²½ê³ ê°€ ìˆìœ¼ë©´ ë¡œê·¸ ì¶œë ¥
    if (configValidation.warnings.length > 0) {
      console.warn('âš ï¸ LLM ì„¤ì • ê²½ê³ :', configValidation.warnings);
    }

    // Request body íŒŒì‹± ë° ê²€ì¦
    const body: GenerateSentenceRequest = await request.json();
    
    if (!body.text || body.text.length === 0) {
      return NextResponse.json(
        { error: 'í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.' },
        { status: 400 }
      );
    }

    if (body.text.length > 500) {
      return NextResponse.json(
        { error: 'í…ìŠ¤íŠ¸ëŠ” 500ì ì´í•˜ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.' },
        { status: 400 }
      );
    }

    if (!['ì´ˆê¸‰', 'ì¤‘ê¸‰', 'ê³ ê¸‰'].includes(body.level)) {
      return NextResponse.json(
        { error: 'ë ˆë²¨ì€ ì´ˆê¸‰, ì¤‘ê¸‰, ê³ ê¸‰ ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.' },
        { status: 400 }
      );
    }

    // ğŸ¤– LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
    const prompt = `ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ${body.level} ìˆ˜ì¤€ì˜ ì˜ì–´ ì˜ˆë¬¸ 3ê°œë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

í…ìŠ¤íŠ¸: "${body.text}"

ìš”êµ¬ì‚¬í•­:
- ${body.level} ìˆ˜ì¤€ì— ë§ëŠ” ì–´íœ˜ì™€ ë¬¸ë²• ì‚¬ìš©
- ìì—°ìŠ¤ëŸ½ê³  ì‹¤ìš©ì ì¸ ë¬¸ì¥
- ê° ë¬¸ì¥ì€ ë…ë¦½ì ì´ê³  ì™„ì „í•œ ë¬¸ì¥ì´ì–´ì•¼ í•¨

í˜•ì‹: ë²ˆí˜¸ ì—†ì´ ë¬¸ì¥ë§Œ ì‘ì„±í•˜ê³ , ê° ë¬¸ì¥ì€ ìƒˆ ì¤„ë¡œ êµ¬ë¶„`;

    // ğŸ”„ ë™ì  LLM í˜¸ì¶œ (primary + fallback ìë™ ì²˜ë¦¬)
    const llmResponse = await callLLM({
      prompt,
      maxTokens: 1000,
      temperature: 0.7
    });

    // ì‘ë‹µ íŒŒì‹±
    const sentences = llmResponse.content
      .split('\n')
      .map(line => line.trim())
      .filter(line => line.length > 0 && !line.match(/^\d+\./)) // ë²ˆí˜¸ ì œê±°
      .slice(0, 3); // ìµœëŒ€ 3ê°œ

    const response: GenerateSentenceResponse = {
      sentences,
      provider: llmResponse.provider  // ğŸ·ï¸ ì‚¬ìš©ëœ LLM provider ì •ë³´ í¬í•¨
    };

    console.log(`âœ… ì˜ì–´ ë¬¸ì¥ ìƒì„± ì™„ë£Œ - Provider: ${llmResponse.provider}, ë¬¸ì¥ ìˆ˜: ${sentences.length}`);
    
    return NextResponse.json(response);

  } catch (error) {
    console.error('âŒ ì˜ì–´ ë¬¸ì¥ ìƒì„± API ì˜¤ë¥˜:', error);
    
    // LLM API ì—°ê²° ì‹¤íŒ¨ ì‹œ ì‚¬ìš©ì ì¹œí™”ì  ë©”ì‹œì§€
    if (error instanceof Error && error.message.includes('API')) {
      return NextResponse.json(
        { 
          error: 'AI ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
          details: process.env.NODE_ENV === 'development' ? error.message : undefined
        },
        { status: 503 }
      );
    }

    return NextResponse.json(
      { error: 'ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' },
      { status: 500 }
    );
  }
}
